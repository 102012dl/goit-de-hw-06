Аналіз результатів виконання завдання зі Spark Streaming
Аналіз відповідності критеріям прийняття
1. Генерація даних сенсорів
У розв'язку було реалізовано скрипт data_generator.py, який успішно генерує потік даних з наступними полями:
id: ідентифікатор сенсора (випадкове число від 1 до 10)
temperature: температура (випадкове значення від 0 до 40°C)
humidity: вологість (випадкове значення від 20 до 90%)
timestamp: часова мітка (поточний час у форматі "YYYY-MM-DD HH:MM:SS")
Ці дані передаються у Kafka-топік "sensor-data" із частотою 1 запис на секунду. Результати виконання скрипту показують, що дані успішно генеруються та відправляються до Kafka.
2. Знаходження середніх значень показників
Реалізовано два підходи до агрегації даних:
Через Spark Streaming (spark_processor.py):
Коректно налаштовано Sliding window тривалістю 1 хвилина
Встановлено sliding_interval на 30 секунд
Налаштовано watermark duration на 10 секунд
Обчислюються середні значення температури та вологості
Через простіший підхід (simple_processor.py):
Реалізовано буфер для зберігання даних
Налаштовано вікно тривалістю 1 хвилина
Встановлено інтервал обробки на 30 секунд
Видаляються застарілі дані (аналог watermark)
Обчислюються середні значення температури та вологості
Результати виконання показують, що обидва підходи успішно агрегують дані та обчислюють середні значення. У виводі скриптів відображаються середні значення температури та вологості, які правильно розраховуються на основі даних, що надходять.
3. Побудова фільтраційного механізму для алертів
У розв'язку реалізовано механізм фільтрації на основі умов, зчитаних із файлу alerts_conditions.csv. Файл містить 5 різних типів алертів з налаштуваннями мінімальних та максимальних значень для температури та вологості.
У Spark-версії використовується crossJoin для об'єднання агрегованих даних з умовами алертів та застосування фільтрації за допомогою складної умови.
У простій версії перевіряється кожна умова алерту через цикл і логічні вирази.
Результати показують, що обидва підходи коректно визначають, коли середні значення виходять за допустимі межі, та генерують відповідні алерти. Наприклад, коли середня температура перевищує 30°C, генерується алерт "TEMP_HIGH", а коли вологість перевищує 80%, генерується алерт "HUM_HIGH".
4. Запис даних у Kafka-топік
Виявлені алерти успішно записуються у Kafka-топік "alerts". Кожен алерт містить:
Код алерту
Повідомлення
Часовий інтервал (початок і кінець вікна)
Середню температуру
Середню вологість
Результати виконання скрипту alerts_consumer.py підтверджують, що алерти успішно записуються в Kafka та можуть бути прочитані споживачем. У виводі споживача відображаються всі деталі алертів у зручному для читання форматі.
Порівняння підходів
Spark Streaming підхід (spark_processor.py)
Переваги:
Використовує повноцінний потужний фреймворк для обробки потоків даних
Має вбудовану підтримку віконних операцій
Легко масштабується для обробки великих обсягів даних
Забезпечує відмовостійкість та гарантує обробку даних
Недоліки:
Складніша налаштування та більше залежностей
Потребує більше ресурсів системи
Може мати проблеми з сумісністю на MacOS
Простіший підхід (simple_processor.py)
Переваги:
Простіший для розуміння та налаштування
Менше залежностей
Працює швидше для невеликих обсягів даних
Краща сумісність з різними платформами
Недоліки:
Обмежені можливості масштабування
Нижча продуктивність для великих обсягів даних
Менша відмовостійкість
